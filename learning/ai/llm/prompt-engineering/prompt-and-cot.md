# Prompt & CoT

| Prompt truncation | <p>AI가 처리할 수 있는 길이를 초과하면<br><strong>프롬프트 일부(보통 앞부분)가 잘리는 것</strong></p> | <p>- 입력 길이가 <br>   너무 길 때<br>- 모델의 토큰 제한 <br>   초과</p> | 엄청 긴 질문을 던졌는데, 앞부분이 날아가서 AI가 제대로 이해 못 함 |
| ----------------- | ----------------------------------------------------------------------- | ------------------------------------------------------ | --------------------------------------- |

| Context loss | AI가 대화 맥락이나 중요한 정보를 **기억하지 못하는 현상** | <p>- 이전 대화가 너무 <br>   길어서 삭제됨<br>- 세션이 종료되어 <br>   AI가 정보를 잊음</p> | 앞에서 "이거 기억해"라고 했는데, 후반부에 가서 AI가 까먹음 |
| ------------ | ----------------------------------- | ----------------------------------------------------------------- | ----------------------------------- |

* Prompt truncation : **입력할 때** 잘리는 것 (던진 문장의 일부가 날아감)
* Context loss : **대화하면서** 정보가 사라지는 거. (기억해야 할 것 까먹음)
* 트렁케이션으로 인해 **중요한 정보가 사라지면** → 대화 맥락이 끊기고 **컨텍스트 손실이 발생**

***

Prompt truncation 해결 방법:

1. 핵심 내용만 담아서 프롬프트를 짧게 유지해라
2. 필요하면 컨텍스트를 다시 리마인드 시켜줘라
3. AI한테 중요한 정보는 "기억하라"고 요청해라

길어진 prompt를 LLM이 추상적으로 나누어 생각할 수 있도록 하자

CoT(Chain of Thought, 생각의사슬)

* 추상적으로 분화시키지 않고 prompt에서 내가 직접 분화시키면 CoT가 아니다

***

### CoT(Chain of Thought)

* CoT과 프롬프팅(Prompting)은 **LLM을 더 똑똑하게 활용하는 핵심적인 기법**이다\
  간단히 말하면 **CoT는 모델이 생각하는 방식**을 유도하는 기법이고, \
  **프롬프팅은 그런 유도를 실제로 입력하는 방식**
* AI가 **단계 별로 논리적인 사고 과정을 거쳐 답을 도출하는 방식**
* 그냥 정답을 내뱉는 게 아니라, 중간 과정까지 생각하면서 답을 내는 것
* AI들은 질문을 받으면 **바로 정답을 예측하려고 했다**.\
  하지만 **CoT 기법을 사용하면**, **AI가 스스로 중간 논리를 생각하면서 더 정확한 답을 낼 수 있음**

#### CoT의 핵심 포인트

1. **사고 과정이 명확해짐** → AI가 더 논리적인 답을 낼 수 있음
2. **복잡한 문제 해결 가능** → 단순 계산이 아니라 **추론, 논리, 응용 문제**도 가능
3. **신뢰성이 높아짐** → "왜 이렇게 답을 내렸는지" 설명 가능

ex)

**(1) 단순한 프롬프팅 (Direct Answer Prompting)**

> **Q:** 철수에게 사과 3개가 있고, 영희에게 사과 5개가 있다. 둘이 합쳐 몇 개의 사과를 가지고 있는가?\
> **A:** 8개.

**(2) CoT 프롬프팅 적용**

> **Q:** 철수에게 사과 3개가 있고, 영희에게 사과 5개가 있다. 둘이 합쳐 몇 개의 사과를 가지고 있는가?\
> **A:**\
> 철수는 사과 3개를 가지고 있다.\
> 영희는 사과 5개를 가지고 있다.\
> 둘이 합치면 3 + 5 = 8개가 된다.\
> 따라서 정답은 8이다.

**차이점:** CoT 방식에서는 중간 과정을 명시함으로써 모델이 논리적으로 답을 유도하도록 만듦

| **프롬프팅 방식**              | **설명**                          | **CoT 적용 여부** |
| ------------------------ | ------------------------------- | ------------- |
| **Direct Prompting**     | 간단한 질문 → 바로 답변                  | ❌             |
| **Zero-shot CoT**        | "생각 과정을 설명해라" → 모델이 직접 사고 과정 생성 | ✅             |
| **Few-shot CoT**         | 예제 몇 개 제공 → 모델이 패턴을 학습하고 따라함    | ✅             |
| **Self-consistency CoT** | 여러 번 답변 생성 후 가장 일관된 답 선택        | ✅             |

***

### Emaxples of CoT Prompting

(1) Zero-shot CoT

```
Q: 철수는 3개의 사과를 가지고 있고, 영희는 5개의 사과를 가지고 있다. 
그들이 가진 사과의 총 개수를 계산하는 과정을 설명하시오.
```

→ 모델이 스스로 논리적 사고 과정을 만들어냄



(2) Few-shot CoT

```
Q: 어떤 숫자가 2배 증가한 후 3을 더하면 13이 된다. 원래 숫자는?
A: 먼저, 어떤 숫자를 x라고 가정한다.
1. 이 숫자를 2배 증가시키면 2x가 된다.
2. 여기에 3을 더하면 2x + 3이 된다.
3. 주어진 식에 따르면 2x + 3 = 13이다.
4. 양변에서 3을 빼면 2x = 10.
5. x = 5가 된다.
따라서 정답은 5이다.
```

→ 모델이 논리적인 사고 과정을 학습하고 더 정확한 답을 내도록 유도

