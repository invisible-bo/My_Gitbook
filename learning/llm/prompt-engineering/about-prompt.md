# About prompt

| Prompt truncation | <p>AI가 처리할 수 있는 길이를 초과하면<br><strong>프롬프트 일부(보통 앞부분)가 잘리는 것</strong></p> | <p>- 입력 길이가 <br>   너무 길 때<br>- 모델의 토큰 제한 <br>   초과</p> | 엄청 긴 질문을 던졌는데, 앞부분이 날아가서 AI가 제대로 이해 못 함 |
| ----------------- | ----------------------------------------------------------------------- | ------------------------------------------------------ | --------------------------------------- |

| Context loss | AI가 대화 맥락이나 중요한 정보를 **기억하지 못하는 현상** | <p>- 이전 대화가 너무 <br>   길어서 삭제됨<br>- 세션이 종료되어 <br>   AI가 정보를 잊음</p> | 앞에서 "이거 기억해"라고 했는데, 후반부에 가서 AI가 까먹음 |
| ------------ | ----------------------------------- | ----------------------------------------------------------------- | ----------------------------------- |

* Prompt truncation : **입력할 때** 잘리는 것 (던진 문장의 일부가 날아감)
* Context loss : **대화하면서** 정보가 사라지는 거. (기억해야 할 것 까먹음)
* 트렁케이션으로 인해 **중요한 정보가 사라지면** → 대화 맥락이 끊기고 **컨텍스트 손실이 발생**

***

Prompt truncation 해결 방법:

1. 핵심 내용만 담아서 프롬프트를 짧게 유지해라
2. 필요하면 컨텍스트를 다시 리마인드 시켜줘라
3. AI한테 중요한 정보는 "기억하라"고 요청해라

길어진 prompt를 LLM이 추상적으로 나누어 생각할 수 있도록 하자

CoT(Chain of Thought, 생각의사슬)

* 추상적으로 분화시키지 않고 prompt에서 내가 직접 분화시키면 CoT가 아니다

***

### CoT(Chain of Thought)

* AI가 **단계 별로 논리적인 사고 과정을 거쳐 답을 도출하는 방식**
* 그냥 정답을 내뱉는 게 아니라, 중간 과정까지 생각하면서 답을 내는 것
* AI들은 질문을 받으면 **바로 정답을 예측하려고 했다**.\
  하지만 **CoT 기법을 사용하면**, **AI가 스스로 중간 논리를 생각하면서 더 정확한 답을 낼 수 있음**

#### CoT의 핵심 포인트

1. **사고 과정이 명확해짐** → AI가 더 논리적인 답을 낼 수 있음
2. **복잡한 문제 해결 가능** → 단순 계산이 아니라 **추론, 논리, 응용 문제**도 가능
3. **신뢰성이 높아짐** → "왜 이렇게 답을 내렸는지" 설명 가능





***

### RAG(Retrieval-Augmented Generation, 검색 증강 생성)

* AI가 기억력 만으로(단순히 학습된 지식) 답을 생성하는 게 아니라, 최신 정보를 검색해서 더 정확한 답을 만들어내는 방식

#### RAG의 작동 방식

1. 검색 (Retrieval)

* AI가 자체 훈련 데이터에 의존하지 않고, **외부 데이터베이스나 검색 엔진에서 최신 정보**를 가져옴
* 예를 들어, **위키 백과, 논문, 문서, API, 뉴스 기사** 등을 검색해서 필요한 정보를 찾음

2. 생성 (Generation)

* 검색한 정보를 바탕으로 **답변을 생성**
* AI가 검색한 내용을 이해하고, 그걸 자연스럽게 풀어서 대답





